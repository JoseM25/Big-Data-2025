{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Laboratorio #5: Normalización\n","___\n","Marcelo Delgado Mora C12510\n","\n","Felipe Mena Rodríguez C24721\n","\n","Jose Mora Monge C15114\n","\n","___\n","En esta práctica se utiliza la herramienta Google Colaboratory. Alternativamente, si gusta puede utilizar Jupyter en línea o instalar Anaconda de manera local, ya que les va a servir para otras actividades más adelante en el curso. Para esta práctica los Notebook deberán crearlo y adaptarlo a las necesidades de su entrega. Esta práctica gira en torno a la normalización de datos.\n","\n","La práctica consiste en ejecutar los ejercicios de la lectura y elegir desarrollar los ejercicios al final de la lectura.\n","\n","##Normalización de datos en Python\n","\n","En esta práctica, se prueban algunas formas diferentes de normalizar datos en Python usando scikit-learn, también conocido como sklearn. Cuando se normalizan datos, se cambia la escala de los datos. Los datos se suelen reescalar para que queden entre 0 y 1, ya que los algoritmos de aprendizaje automático tienden a funcionar mejor, o convergen más rápido, cuando las diferentes características están en una escala más pequeña. Antes de entrenar modelos de aprendizaje automático con datos, es una práctica común normalizar los datos primero para obtener resultados potencialmente mejores y más rápidos. La normalización también hace que el proceso de entrenamiento sea menos sensible a la escala de las características, lo que da como resultado mejores coeficientes después del entrenamiento.\n","\n","Este proceso de hacer que las características sean más adecuadas para el entrenamiento mediante el reescalado se llama escalado de características.\n","\n","* Python versión 3.9.13\n","* scikit-learn versión 1.0.2.\n","\n","###La función preprocessing.normalize()\n","\n","La función preprocessing.normalize() de scikit-learn se puede utilizar para normalizar un conjunto de datos similar a una matriz.\n","\n","La función normalize() escala los vectores individualmente a una norma unitaria para que el vector tenga una longitud de uno. La norma predeterminada para normalize() es L2, también conocida como norma euclidiana. La fórmula de la norma L2 es la raíz cuadrada de la suma de los cuadrados de cada valor. Aunque el uso de la función normalize() da como resultado valores entre 0 y 1, no es lo mismo que simplemente escalar los valores para que queden entre 0 y 1.\n","\n","####Normalización de una matriz utilizando la función normalize()\n","\n","Se puede normalizar una matriz NumPy unidimensional utilizando la función normalize().\n","\n","Para ello, se debe importar el módulo sklearn.preprocessing:"],"metadata":{"id":"sZ85uvQdUApu"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"9kSOit0vT4Ol","executionInfo":{"status":"ok","timestamp":1767857436516,"user_tz":480,"elapsed":2049,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}}},"outputs":[],"source":["from sklearn import preprocessing"]},{"cell_type":"markdown","source":["Se importa NumPy y se crea una matriz."],"metadata":{"id":"jForSF37VHFi"}},{"cell_type":"code","source":["import numpy as np\n","\n","x_array = np.array([2,3,5,6,7,4,8,7,6])"],"metadata":{"id":"wmyJef0GVdWP","executionInfo":{"status":"ok","timestamp":1767857437908,"user_tz":480,"elapsed":11,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Se usa la función normalize() en la matriz para normalizar los datos a lo largo de una fila, en este caso una matriz unidimensional."],"metadata":{"id":"YXEqEK4EVc6R"}},{"cell_type":"code","source":["normalized_arr = preprocessing.normalize([x_array])\n","print(normalized_arr)"],"metadata":{"id":"aC5snHyuVmjN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857439262,"user_tz":480,"elapsed":6,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"a7cd3f49-6a67-4887-90e5-aad7ccb872b4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.11785113 0.1767767  0.29462783 0.35355339 0.41247896 0.23570226\n","  0.47140452 0.41247896 0.35355339]]\n"]}]},{"cell_type":"markdown","source":["Se ejecuta el código de ejemplo completo para demostrar cómo normalizar una matriz NumPy utilizando la función normalize()."],"metadata":{"id":"_AkFIhgcVw_h"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import numpy as np\n","\n","x_array = np.array([2,3,5,6,7,4,8,7,6])\n","\n","normalized_arr = preprocessing.normalize([x_array])\n","print(normalized_arr)"],"metadata":{"id":"xFeA3Wp_VxVS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857440615,"user_tz":480,"elapsed":3,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"5cfd6b31-11a7-4e51-df69-22f17e5a8b95"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.11785113 0.1767767  0.29462783 0.35355339 0.41247896 0.23570226\n","  0.47140452 0.41247896 0.35355339]]\n"]}]},{"cell_type":"markdown","source":["La salida muestra que todos los valores están en el rango de 0 a 1. Si se elevan al cuadrado todos los valores de la salida y luego se suman, el resultado es 1, o muy cercano a 1.\n","\n","####Normalización de columnas de un DataFrame utilizando la función normalize()\n","\n","En un DataFrame de pandas, las características son columnas y las filas son muestras. Se puede convertir una columna de DataFrame en una matriz NumPy y luego normalizar los datos en la matriz.\n","\n","Los ejemplos en esta sección y en las siguientes utilizan el conjunto de datos [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset).\n","\n","La primera parte del código de ejemplo importa los módulos, carga el conjunto de datos, crea el DataFrame e imprime la descripción del conjunto de datos."],"metadata":{"id":"o7nJr1MLV7lH"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import preprocessing\n","from sklearn.datasets import fetch_california_housing\n","\n","# create the DataFrame\n","california_housing = fetch_california_housing(as_frame=True)\n","\n","# print the dataset description\n","print(california_housing.DESCR)"],"metadata":{"id":"ALiC0hEdWZ78","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857446271,"user_tz":480,"elapsed":3674,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"a5145961-487d-4ff7-e036-5fc93e05c478"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _california_housing_dataset:\n","\n","California Housing dataset\n","--------------------------\n","\n","**Data Set Characteristics:**\n","\n",":Number of Instances: 20640\n","\n",":Number of Attributes: 8 numeric, predictive attributes and the target\n","\n",":Attribute Information:\n","    - MedInc        median income in block group\n","    - HouseAge      median house age in block group\n","    - AveRooms      average number of rooms per household\n","    - AveBedrms     average number of bedrooms per household\n","    - Population    block group population\n","    - AveOccup      average number of household members\n","    - Latitude      block group latitude\n","    - Longitude     block group longitude\n","\n",":Missing Attribute Values: None\n","\n","This dataset was obtained from the StatLib repository.\n","https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n","\n","The target variable is the median house value for California districts,\n","expressed in hundreds of thousands of dollars ($100,000).\n","\n","This dataset was derived from the 1990 U.S. census, using one row per census\n","block group. A block group is the smallest geographical unit for which the U.S.\n","Census Bureau publishes sample data (a block group typically has a population\n","of 600 to 3,000 people).\n","\n","A household is a group of people residing within a home. Since the average\n","number of rooms and bedrooms in this dataset are provided per household, these\n","columns may take surprisingly large values for block groups with few households\n","and many empty houses, such as vacation resorts.\n","\n","It can be downloaded/loaded using the\n",":func:`sklearn.datasets.fetch_california_housing` function.\n","\n",".. rubric:: References\n","\n","- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n","  Statistics and Probability Letters, 33 (1997) 291-297\n","\n"]}]},{"cell_type":"markdown","source":["Se observa que el parámetro as_frame está establecido en True para crear el objeto california_housing como un DataFrame de pandas. La salida incluye el siguiente extracto de la descripción del conjunto de datos, que se puede utilizar para elegir una característica para normalizar.\n","\n","Se convierte una columna (característica) en una matriz y se imprime. Este ejemplo utiliza la columna HouseAge."],"metadata":{"id":"TshzYIC6Wzi9"}},{"cell_type":"code","source":["x_array = np.array(california_housing.data[\"HouseAge\"])\n","print(\"HouseAge array: \",x_array)"],"metadata":{"id":"lxc33uRfXKAE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857450022,"user_tz":480,"elapsed":3,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"aa3da7ba-bd7c-4fd0-a9ef-003f0cdfd9b5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["HouseAge array:  [41. 21. 52. ... 17. 18. 16.]\n"]}]},{"cell_type":"markdown","source":["Se utiliza la función normalize() para normalizar los datos y se imprime la matriz resultante."],"metadata":{"id":"b0Smu4veXOZE"}},{"cell_type":"code","source":["normalized_arr = preprocessing.normalize([x_array])\n","print(\"Normalized HouseAge array: \",normalized_arr)"],"metadata":{"id":"LBS028IBXOo4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857451692,"user_tz":480,"elapsed":17,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"d98e523a-ad63-4de6-ec92-fa65c90a8310"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Normalized HouseAge array:  [[0.00912272 0.00467261 0.01157028 ... 0.00378259 0.0040051  0.00356009]]\n"]}]},{"cell_type":"markdown","source":["Se ejecuta el ejemplo completo para demostrar cómo normalizar una característica utilizando la función normalize()."],"metadata":{"id":"AEkBp9BbXO23"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import numpy as np\n","from sklearn.datasets import fetch_california_housing\n","\n","california_housing = fetch_california_housing(as_frame=True)\n","# print(california_housing.DESCR)\n","\n","x_array = np.array(california_housing.data['HouseAge'])\n","print(\"HouseAge array: \",x_array)\n","\n","normalized_arr = preprocessing.normalize([x_array])\n","print(\"Normalized HouseAge array: \",normalized_arr)"],"metadata":{"id":"MpPFlMbAXPMN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857453210,"user_tz":480,"elapsed":26,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"5a908c39-49b8-4241-bd2d-4a37f4efd409"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["HouseAge array:  [41. 21. 52. ... 17. 18. 16.]\n","Normalized HouseAge array:  [[0.00912272 0.00467261 0.01157028 ... 0.00378259 0.0040051  0.00356009]]\n"]}]},{"cell_type":"markdown","source":["La salida muestra que la función normalize() cambió la matriz de valores de edad media de la casa de modo que la raíz cuadrada de la suma de los cuadrados de los valores es igual a uno. En otras palabras, los valores se escalaron a una longitud unitaria utilizando la norma L2.\n","\n","####Normalización de conjuntos de datos por fila o columna utilizando la función normalize()\n","\n","Cuando se normaliza un conjunto de datos sin convertir las características, o columnas, en matrices para su procesamiento, los datos se normalizan por fila. El eje predeterminado para la función normalize() es 1, lo que significa que cada muestra, o fila, se normaliza.\n","\n","El siguiente ejemplo demuestra cómo normalizar el conjunto de datos California Housing utilizando el eje predeterminado."],"metadata":{"id":"EcI2xFv4XPjK"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import pandas as pd\n","\n","from sklearn.datasets import fetch_california_housing\n","california_housing = fetch_california_housing(as_frame=True)\n","\n","d = preprocessing.normalize(california_housing.data)\n","scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)\n","print(scaled_df)"],"metadata":{"id":"9uZwTOVoXPxk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857455411,"user_tz":480,"elapsed":61,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"2dcce11f-124c-45d0-880e-16e1c10d4c66"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n","0      0.023848  0.117447  0.020007   0.002933    0.922391  0.007321   \n","1      0.003452  0.008734  0.002594   0.000404    0.998535  0.000877   \n","2      0.014092  0.100971  0.016093   0.002084    0.963106  0.005441   \n","3      0.009816  0.090449  0.010119   0.001866    0.970590  0.004432   \n","4      0.006612  0.089394  0.010799   0.001859    0.971303  0.003750   \n","...         ...       ...       ...        ...         ...       ...   \n","20635  0.001825  0.029242  0.005902   0.001326    0.988384  0.002995   \n","20636  0.006753  0.047539  0.016147   0.003475    0.940212  0.008247   \n","20637  0.001675  0.016746  0.005128   0.001103    0.991926  0.002291   \n","20638  0.002483  0.023932  0.007086   0.001558    0.985188  0.002823   \n","20639  0.001715  0.011486  0.003772   0.000834    0.995727  0.001879   \n","\n","       Latitude  Longitude  \n","0      0.108510  -0.350136  \n","1      0.015745  -0.050829  \n","2      0.073495  -0.237359  \n","3      0.065837  -0.212643  \n","4      0.065069  -0.210162  \n","...         ...        ...  \n","20635  0.046179  -0.141637  \n","20636  0.104295  -0.320121  \n","20637  0.038840  -0.119405  \n","20638  0.052424  -0.161300  \n","20639  0.028264  -0.087038  \n","\n","[20640 rows x 8 columns]\n"]}]},{"cell_type":"markdown","source":["La salida muestra que los valores se normalizan a lo largo de las filas de modo que cada muestra se normaliza en lugar de cada característica. Se puede normalizar por característica especificando el eje.\n","\n","El siguiente ejemplo demuestra cómo normalizar el conjunto de datos California Housing utilizando axis=0 para normalizar por característica."],"metadata":{"id":"6KnROrZkYAwZ"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import pandas as pd\n","\n","from sklearn.datasets import fetch_california_housing\n","california_housing = fetch_california_housing(as_frame=True)\n","\n","d = preprocessing.normalize(california_housing.data, axis=0)\n","scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)\n","print(scaled_df)"],"metadata":{"id":"dhvFz-euYAiy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857457253,"user_tz":480,"elapsed":31,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"0c98107c-c77d-4c82-ad46-b1dba72e1c3f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n","0      0.013440  0.009123  0.008148   0.005965    0.001231  0.001642   \n","1      0.013401  0.004673  0.007278   0.005662    0.009180  0.001356   \n","2      0.011716  0.011570  0.009670   0.006254    0.001896  0.001801   \n","3      0.009110  0.011570  0.006787   0.006252    0.002133  0.001638   \n","4      0.006209  0.011570  0.007329   0.006299    0.002160  0.001402   \n","...         ...       ...       ...        ...         ...       ...   \n","20635  0.002519  0.005563  0.005886   0.006603    0.003231  0.001646   \n","20636  0.004128  0.004005  0.007133   0.007666    0.001361  0.002007   \n","20637  0.002744  0.003783  0.006073   0.006526    0.003850  0.001495   \n","20638  0.003014  0.004005  0.006218   0.006828    0.002833  0.001365   \n","20639  0.003856  0.003560  0.006131   0.006772    0.005303  0.001682   \n","\n","       Latitude  Longitude  \n","0      0.007386  -0.007114  \n","1      0.007383  -0.007114  \n","2      0.007381  -0.007115  \n","3      0.007381  -0.007116  \n","4      0.007381  -0.007116  \n","...         ...        ...  \n","20635  0.007698  -0.007048  \n","20636  0.007700  -0.007055  \n","20637  0.007689  -0.007056  \n","20638  0.007689  -0.007061  \n","20639  0.007677  -0.007057  \n","\n","[20640 rows x 8 columns]\n"]}]},{"cell_type":"markdown","source":["Cuando se examine la salida, se observará que los resultados de la columna HouseAge coinciden con la salida que se obtuvo cuando se convirtió la columna HouseAge a una matriz y se normalizó en un ejemplo anterior.\n","\n","###Uso de la función preprocessing.MinMaxScaler() de scikit-learn para normalizar datos\n","\n","Puede utilizar la función preprocessing.MinMaxScaler() de scikit-learn para normalizar cada característica escalando los datos a un rango.\n","\n","La función MinMaxScaler() escala cada característica individualmente para que los valores tengan un valor mínimo y máximo determinado, con un valor predeterminado de 0 y 1.\n","\n","La fórmula para escalar los valores de las características a entre 0 y 1 es:\n","\n","`scaled_value = (original_value - min_value) / (max_value - min_value)`\n","\n","Se resta el valor mínimo de cada entrada y luego se divide el resultado por el rango, donde el rango es la diferencia entre el valor máximo y el valor mínimo.\n","\n","El siguiente ejemplo demuestra cómo se utiliza la función MinMaxScaler() para normalizar el conjunto de datos California Housing."],"metadata":{"id":"X2Nd2x00Ybmg"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import pandas as pd\n","\n","from sklearn.datasets import fetch_california_housing\n","california_housing = fetch_california_housing(as_frame=True)\n","\n","scaler = preprocessing.MinMaxScaler()\n","d = scaler.fit_transform(california_housing.data)\n","scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)\n","print(scaled_df)"],"metadata":{"id":"QC_MNkmcYnAl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857460065,"user_tz":480,"elapsed":9,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"6bfdfafa-4930-407c-e5e9-595c715666ec"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n","0      0.539668  0.784314  0.043512   0.020469    0.008941  0.001499   \n","1      0.538027  0.392157  0.038224   0.018929    0.067210  0.001141   \n","2      0.466028  1.000000  0.052756   0.021940    0.013818  0.001698   \n","3      0.354699  1.000000  0.035241   0.021929    0.015555  0.001493   \n","4      0.230776  1.000000  0.038534   0.022166    0.015752  0.001198   \n","...         ...       ...       ...        ...         ...       ...   \n","20635  0.073130  0.470588  0.029769   0.023715    0.023599  0.001503   \n","20636  0.141853  0.333333  0.037344   0.029124    0.009894  0.001956   \n","20637  0.082764  0.313725  0.030904   0.023323    0.028140  0.001314   \n","20638  0.094295  0.333333  0.031783   0.024859    0.020684  0.001152   \n","20639  0.130253  0.294118  0.031252   0.024573    0.038790  0.001549   \n","\n","       Latitude  Longitude  \n","0      0.567481   0.211155  \n","1      0.565356   0.212151  \n","2      0.564293   0.210159  \n","3      0.564293   0.209163  \n","4      0.564293   0.209163  \n","...         ...        ...  \n","20635  0.737513   0.324701  \n","20636  0.738576   0.312749  \n","20637  0.732200   0.311753  \n","20638  0.732200   0.301793  \n","20639  0.725824   0.309761  \n","\n","[20640 rows x 8 columns]\n"]}]},{"cell_type":"markdown","source":["La salida muestra que los valores se escalan para tener un valor mínimo predeterminado de 0 y un valor máximo de 1.\n","\n","También se pueden especificar diferentes valores mínimo y máximo para la escala. En el siguiente ejemplo, el valor mínimo es 0 y el valor máximo es 2."],"metadata":{"id":"9APL1qNPZAKq"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import pandas as pd\n","\n","from sklearn.datasets import fetch_california_housing\n","california_housing = fetch_california_housing(as_frame=True)\n","\n","scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))\n","d = scaler.fit_transform(california_housing.data)\n","scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)\n","print(scaled_df)"],"metadata":{"id":"wp8YSz1-Y_QH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857462404,"user_tz":480,"elapsed":33,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"0da00280-d4d5-4ca7-b6d3-90a42c099927"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n","0      1.079337  1.568627  0.087025   0.040937    0.017882  0.002999   \n","1      1.076054  0.784314  0.076448   0.037859    0.134421  0.002281   \n","2      0.932056  2.000000  0.105513   0.043880    0.027635  0.003396   \n","3      0.709397  2.000000  0.070482   0.043857    0.031111  0.002987   \n","4      0.461552  2.000000  0.077068   0.044333    0.031503  0.002397   \n","...         ...       ...       ...        ...         ...       ...   \n","20635  0.146260  0.941176  0.059538   0.047431    0.047199  0.003007   \n","20636  0.283706  0.666667  0.074688   0.058248    0.019788  0.003912   \n","20637  0.165529  0.627451  0.061808   0.046646    0.056280  0.002629   \n","20638  0.188591  0.666667  0.063565   0.049719    0.041369  0.002303   \n","20639  0.260507  0.588235  0.062505   0.049146    0.077581  0.003098   \n","\n","       Latitude  Longitude  \n","0      1.134963   0.422311  \n","1      1.130712   0.424303  \n","2      1.128587   0.420319  \n","3      1.128587   0.418327  \n","4      1.128587   0.418327  \n","...         ...        ...  \n","20635  1.475027   0.649402  \n","20636  1.477152   0.625498  \n","20637  1.464400   0.623506  \n","20638  1.464400   0.603586  \n","20639  1.451647   0.619522  \n","\n","[20640 rows x 8 columns]\n"]}]},{"cell_type":"markdown","source":["La salida muestra que los valores se escalan para tener un valor mínimo de 0 y un valor máximo de 2.\n","\n","##Ejercicio de Normalización\n","\n","1) Busque un dataset al cuál aplicar normalización a al menos un atributo.\n","\n"],"metadata":{"id":"uidi_MhVZk1y"}},{"cell_type":"code","source":["from sklearn.datasets import load_diabetes\n","diabetes = load_diabetes(as_frame=True, scaled=False)\n","print(diabetes.DESCR)\n","print(diabetes)"],"metadata":{"id":"sJhzC7olbRtt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857464714,"user_tz":480,"elapsed":108,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"c12940d1-8f48-4b6c-dfe8-4585a538e8c7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _diabetes_dataset:\n","\n","Diabetes dataset\n","----------------\n","\n","Ten baseline variables, age, sex, body mass index, average blood\n","pressure, and six blood serum measurements were obtained for each of n =\n","442 diabetes patients, as well as the response of interest, a\n","quantitative measure of disease progression one year after baseline.\n","\n","**Data Set Characteristics:**\n","\n",":Number of Instances: 442\n","\n",":Number of Attributes: First 10 columns are numeric predictive values\n","\n",":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n","\n",":Attribute Information:\n","    - age     age in years\n","    - sex\n","    - bmi     body mass index\n","    - bp      average blood pressure\n","    - s1      tc, total serum cholesterol\n","    - s2      ldl, low-density lipoproteins\n","    - s3      hdl, high-density lipoproteins\n","    - s4      tch, total cholesterol / HDL\n","    - s5      ltg, possibly log of serum triglycerides level\n","    - s6      glu, blood sugar level\n","\n","Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n","\n","Source URL:\n","https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n","\n","For more information see:\n","Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n","(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n","\n","{'data':       age  sex   bmi      bp     s1     s2    s3    s4      s5     s6\n","0    59.0  2.0  32.1  101.00  157.0   93.2  38.0  4.00  4.8598   87.0\n","1    48.0  1.0  21.6   87.00  183.0  103.2  70.0  3.00  3.8918   69.0\n","2    72.0  2.0  30.5   93.00  156.0   93.6  41.0  4.00  4.6728   85.0\n","3    24.0  1.0  25.3   84.00  198.0  131.4  40.0  5.00  4.8903   89.0\n","4    50.0  1.0  23.0  101.00  192.0  125.4  52.0  4.00  4.2905   80.0\n","..    ...  ...   ...     ...    ...    ...   ...   ...     ...    ...\n","437  60.0  2.0  28.2  112.00  185.0  113.8  42.0  4.00  4.9836   93.0\n","438  47.0  2.0  24.9   75.00  225.0  166.0  42.0  5.00  4.4427  102.0\n","439  60.0  2.0  24.9   99.67  162.0  106.6  43.0  3.77  4.1271   95.0\n","440  36.0  1.0  30.0   95.00  201.0  125.2  42.0  4.79  5.1299   85.0\n","441  36.0  1.0  19.6   71.00  250.0  133.2  97.0  3.00  4.5951   92.0\n","\n","[442 rows x 10 columns], 'target': 0      151.0\n","1       75.0\n","2      141.0\n","3      206.0\n","4      135.0\n","       ...  \n","437    178.0\n","438    104.0\n","439    132.0\n","440    220.0\n","441     57.0\n","Name: target, Length: 442, dtype: float64, 'frame':       age  sex   bmi      bp     s1     s2    s3    s4      s5     s6  target\n","0    59.0  2.0  32.1  101.00  157.0   93.2  38.0  4.00  4.8598   87.0   151.0\n","1    48.0  1.0  21.6   87.00  183.0  103.2  70.0  3.00  3.8918   69.0    75.0\n","2    72.0  2.0  30.5   93.00  156.0   93.6  41.0  4.00  4.6728   85.0   141.0\n","3    24.0  1.0  25.3   84.00  198.0  131.4  40.0  5.00  4.8903   89.0   206.0\n","4    50.0  1.0  23.0  101.00  192.0  125.4  52.0  4.00  4.2905   80.0   135.0\n","..    ...  ...   ...     ...    ...    ...   ...   ...     ...    ...     ...\n","437  60.0  2.0  28.2  112.00  185.0  113.8  42.0  4.00  4.9836   93.0   178.0\n","438  47.0  2.0  24.9   75.00  225.0  166.0  42.0  5.00  4.4427  102.0   104.0\n","439  60.0  2.0  24.9   99.67  162.0  106.6  43.0  3.77  4.1271   95.0   132.0\n","440  36.0  1.0  30.0   95.00  201.0  125.2  42.0  4.79  5.1299   85.0   220.0\n","441  36.0  1.0  19.6   71.00  250.0  133.2  97.0  3.00  4.5951   92.0    57.0\n","\n","[442 rows x 11 columns], 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 442\\n\\n:Number of Attributes: First 10 columns are numeric predictive values\\n\\n:Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n:Attribute Information:\\n    - age     age in years\\n    - sex\\n    - bmi     body mass index\\n    - bp      average blood pressure\\n    - s1      tc, total serum cholesterol\\n    - s2      ldl, low-density lipoproteins\\n    - s3      hdl, high-density lipoproteins\\n    - s4      tch, total cholesterol / HDL\\n    - s5      ltg, possibly log of serum triglycerides level\\n    - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': 'diabetes_data_raw.csv.gz', 'target_filename': 'diabetes_target.csv.gz', 'data_module': 'sklearn.datasets.data'}\n"]}]},{"cell_type":"markdown","source":["2) Aplique un método de normalización al dataset para los atributos seleccionados."],"metadata":{"id":"3bWlEw38bUNe"}},{"cell_type":"code","source":["x_array = np.array(diabetes.data[['age','bmi','bp']])\n","print(\"Original array:\\n\\n\",x_array)\n","\n","print('_____________________________________________________________\\nNormalized Array as DF:\\n')\n","d = preprocessing.normalize(x_array, axis=0)\n","scaled_df = pd.DataFrame(d, columns=['age', 'bmi', 'bp'])\n","print(scaled_df)"],"metadata":{"id":"rY0g_yhebUhV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767857467839,"user_tz":480,"elapsed":14,"user":{"displayName":"Jose Mora","userId":"15431928474094312772"}},"outputId":"78c1dd75-6d29-4431-f75a-5d5490d397a8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original array:\n","\n"," [[ 59.    32.1  101.  ]\n"," [ 48.    21.6   87.  ]\n"," [ 72.    30.5   93.  ]\n"," ...\n"," [ 60.    24.9   99.67]\n"," [ 36.    30.    95.  ]\n"," [ 36.    19.6   71.  ]]\n","_____________________________________________________________\n","Normalized Array as DF:\n","\n","          age       bmi        bp\n","0    0.055843  0.057094  0.050226\n","1    0.045432  0.038419  0.043264\n","2    0.068148  0.054248  0.046247\n","3    0.022716  0.045000  0.041772\n","4    0.047325  0.040909  0.050226\n","..        ...       ...       ...\n","437  0.056790  0.050158  0.055696\n","438  0.044485  0.044288  0.037296\n","439  0.056790  0.044288  0.049564\n","440  0.034074  0.053359  0.047242\n","441  0.034074  0.034861  0.035307\n","\n","[442 rows x 3 columns]\n"]}]},{"cell_type":"markdown","source":["3) Explique la importancia de normalizar los atributos seleccionados para el análisis del dataset."],"metadata":{"id":"UaoDTpoLb2nZ"}},{"cell_type":"markdown","source":["Es necesario para que los datos se encuentren dentro de un mismo rango o escala, de forma que ninguno pueda sobreponerse a otro y tenga un peso o dominio mayor que el resto.\n","\n","Además, es útil a la hora de utilizar los datos en disciplinas como el Machine\n","Learning, debido a que datos normalizados entre un rango pequeño ayuda a que\n","el proceso de entrenamiento del modelo tenga una menor duración y converja más\n","rápido."],"metadata":{"id":"frciq6Jbb23H"}},{"cell_type":"markdown","source":["##Conclusión\n","\n","Se han utilizado dos funciones de scikit-learn para normalizar los datos de diferentes maneras por muestra (fila) y por característica (columna).\n","\n","Fuentes:\n","\n","* [Sklearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html)\n","* [How to Normalize Data Using scikit-learn in Python](https://www.digitalocean.com/community/tutorials/normalize-data-in-python)\n"],"metadata":{"id":"wHi_FSIIbSGg"}}]}